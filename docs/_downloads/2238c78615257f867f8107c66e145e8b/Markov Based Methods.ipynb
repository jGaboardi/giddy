{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSpatially Explicit Markov Methods\n=================================\n\n**Author: Serge Rey sjsrey@gmail.com, Wei Kang weikang9009@gmail.com**\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Introduction\n------------\n\nThis notebook introduces Discrete Markov Chains (DMC) model and its two\nvariants which explicitly incorporate spatial effects. We will\ndemonstrate the usage of these methods by an empirical study for\nunderstanding `regional income dynamics in the\nUS <#Regional-income-dynamics-in-the-US>`__. The dataset is the per\ncapita incomes observed annually from 1929 to 2009 for the lower 48 US\nstates.\n\n-  `Classic Markov <#Classic-Markov>`__\n-  `Spatial Markov <#Spatial-Markov>`__\n-  `LISA Markov <#LISA-Markov>`__\n\nNote that a full execution of this notebook requires **pandas**,\n**matplotlib** and light-weight geovisualization package\npysal-\\ **splot**.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classic Markov\n~~~~~~~~~~~~~~\n\n::\n\n    giddy.markov.Markov(self, class_ids, classes=None)\n\nWe start with a look at a simple example of classic DMC methods\nimplemented in PySAL-giddy. A Markov chain may be in one of $k$\ndifferent states/classes at any point in time. These states are\nexhaustive and mutually exclusive. If one had a time series of remote\nsensing images used to develop land use classifications, then the states\ncould be defined as the specific land use classes and interest would\ncenter on the transitions in and out of different classes for each\npixel.\n\nFor example, suppose there are 5 pixels, each of which takes on one of 3\nstates (a,b,c) at 3 consecutive periods:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nc = np.array([['b','a','c'],['c','c','a'],['c','b','c'],['a','a','b'],['a','b','c']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So the first pixel was in state \u2018b\u2019 in period 1, state \u2018a\u2019 in period 2,\nand state \u2018c\u2019 in period 3. Each pixel's trajectory (row) owns `Markov\nproperty <https://en.wikipedia.org/wiki/Markov_property>`__, meaning\nthat which state a pixel takes on today is only dependent on its\nimmediate past.\n\nLet's suppose that all the 5 pixels are governed by the same transition\ndynamics rule. That is, each trajectory is a realization of a Discrete\nMarkov Chain process. We could pool all the 5 trajectories from which to\nestimate a transition probability matrix. To do that, we utlize the\n**Markov** class in **giddy**:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import giddy\nm = giddy.markov.Markov(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this way, we create a **Markov** instance - $m$. Its attribute\n$classes$ gives 3 unique classes these pixels can take on, which\nare 'a','b' and 'c'.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(m.classes)\n\nprint(len(m.classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition to extracting the unique states as an attribute, our\n**Markov** instance will also have the attribute *trnasitions* which is\na transition matrix counting the number of transitions from one state to\nanother. Since there are 3 unique states, we will have a $(3,3)$\ntranstion matrix:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(m.transitions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above transition matrix indicates that of the four pixels that began\na transition interval in state \u2018a\u2019, 1 remained in that state, 2\ntransitioned to state \u2018b\u2019 and 1 transitioned to state \u2018c\u2019. Another\nattribute $p$ gives the transtion probability matrix which is the\ntransition dynamics rule ubiquitous to all the 5 pixels across the 3\nperiods. The maximum likehood estimator for each element $p_{i,j}$\nis shown below where $n_{i,j}$ is the number of transitions from\nstate $i$ to state $j$ and $k$ is the number of states\n(here $k=3$):\n\n\\begin{align}\\hat{p}_{i,j} = \\frac{n_{i,j}}{\\sum_{q=1}^k n_{i,q} }\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(m.p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This means that if any of the 5 pixels was in state 'c', the probability\nof staying at 'c' or transitioning to any other states ('a', 'b') in the\nnext period is the same (0.333). If a pixel was in state 'b', there is a\nhigh possibility that it would take on state 'c' in the next period\nbecause $\\hat{p}_{2,3}=0.667$.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This simple example illustrates the basic creation of a Markov instance,\nbut the small sample size makes it unrealistic for the more advanced\nfeatures of this approach. For a larger example, we will look at an\napplication of Markov methods to understanding regional income dynamics\nin the US. Here we will load in data on per capita incomes observed\nannually from 1929 to 2010 for the lower 48 US states:\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regional income dynamics in the US\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFirstly, we load in data on per capita incomes observed annually from\n1929 to 2009 for the lower 48 US states. We use the example dataset in\n`**libpysal** <https://github.com/pysal/libpysal>`__ which was\ndownloaded from `US Bureau of Economic\nAnalysis <https://www.bea.gov>`__.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import libpysal\nf = libpysal.open(libpysal.examples.get_path(\"usjoin.csv\"))\npci = np.array([f.by_col[str(y)] for y in range(1929,2010)])\nprint(pci.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first row of the array is the per capita incomes for the 48 US\nstates for the year 1929:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(pci[0, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to apply the classic Markov approach to this series, we first\nhave to discretize the distribution by defining our classes. There are\nmany ways to do this including quantiles classification scheme, equal\ninterval classification scheme, Fisher Jenks classification scheme, etc.\nFor a list of classification methods, please refer to the pysal package\n`**mapclassify** <https://github.com/pysal/mapclassify>`__.\n\nHere we will use the quintiles for each annual income distribution to\ndefine the classes. It should be noted that using quintiles for the\npooled income distribution to define the classes will result in a\ndifferent interpretation of the income dynamics. Quintiles for each\nannual income distribution (the former) will reveal more of relative\nincome dynamics while those for the pooled income distribution (the\nlatter) will provide insights in absolute dynamics.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n# %matplotlib inline\nyears = range(1929,2010)\nnames = np.array(f.by_col(\"Name\"))\norder1929 = np.argsort(pci[0,:])\norder2009 = np.argsort(pci[-1,:])\nnames1929 = names[order1929[::-1]]\nnames2009 = names[order2009[::-1]]\nfirst_last = np.vstack((names[order1929[::-1]],names[order2009[::-1]]))\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15,10\nplt.plot(years,pci)\nfor i in range(48):\n    plt.text(1915,54530-(i*1159), names1929[i],fontsize=12)\n    plt.text(2010.5,54530-(i*1159), names2009[i],fontsize=12)\nplt.xlim((years[0], years[-1]))\nplt.ylim((0, 54530))\nplt.ylabel(r\"$y_{i,t}$\",fontsize=14)\nplt.xlabel('Years',fontsize=12)\nplt.title('Absolute Dynamics',fontsize=18)\n\nyears = range(1929,2010)\nrpci= (pci.T / pci.mean(axis=1)).T\nnames = np.array(f.by_col(\"Name\"))\norder1929 = np.argsort(rpci[0,:])\norder2009 = np.argsort(rpci[-1,:])\nnames1929 = names[order1929[::-1]]\nnames2009 = names[order2009[::-1]]\nfirst_last = np.vstack((names[order1929[::-1]],names[order2009[::-1]]))\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15,10\nplt.plot(years,rpci)\nfor i in range(48):\n    plt.text(1915,1.91-(i*0.041), names1929[i],fontsize=12)\n    plt.text(2010.5,1.91-(i*0.041), names2009[i],fontsize=12)\nplt.xlim((years[0], years[-1]))\nplt.ylim((0, 1.94))\nplt.ylabel(r\"$y_{i,t}/\\bar{y}_t$\",fontsize=14)\nplt.xlabel('Years',fontsize=12)\nplt.title('Relative Dynamics',fontsize=18)\n\nimport mapclassify.api as mc\nq5 = np.array([mc.Quantiles(y,k=5).yb for y in pci]).transpose()\nprint(q5[:, 0])\n\nprint(f.by_col(\"Name\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A number of things need to be noted here. First, we are relying on the\nclassification methods in\n`**mapclassify** <https://github.com/pysal/mapclassify>`__ for defining\nour quintiles. The class *Quantiles* uses quintiles ($k=5$) as the\ndefault and will create an instance of this class that has multiple\nattributes, the one we are extracting in the first line is $yb$ -\nthe class id for each observation. The second thing to note is the\ntranspose operator which gets our resulting array $q5$ in the\nproper structure required for use of Markov. Thus we see that the first\nspatial unit (Alabama with an income of 323) fell in the first quintile\nin 1929, while the last unit (Wyoming with an income of 675) fell in the\nfourth quintile.\n\nSo now we have a time series for each state of its quintile membership.\nFor example, Colorado\u2019s quintile time series is:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(q5[4, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "indicating that it has occupied the 3rd, 4th and 5th quintiles in the\ndistribution at the first 3 periods. To summarize the transition\ndynamics for all units, we instantiate a Markov object:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "m5 = giddy.markov.Markov(q5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of transitions between any two quintile classes could be\ncounted:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(m5.transitions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By assuming the first-order Markov property, time homogeneity, spatial\nhomogeneity and spatial independence, a transition probability matrix\ncould be estimated which holds for all the 48 US states across\n1929-2010:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(m5.p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fact that each of the 5 diagonal elements is larger than\n$0.78$ indicates a high stability of US regional income dynamics\nsystem.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another very important feature of DMC model is the steady state\ndistribution $\\pi$ (also called limiting distribution) defined as\n$\\pi p = \\pi$. The attribute $steady\\_state$ gives\n$\\pi$ as follows:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(m5.steady_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the distribution at $t$ is a steady state distribution as shown\nabove, then any distribution afterwards is the same distribution.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the transition probability matrix in hand, we can estimate the\nfirst mean passage time which is the average number of steps to go from\na state/class to another state for the first time:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(giddy.ergodic.fmpt(m5.p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, for a state with income in the first quintile, it takes on average\n11.5 years for it to first enter the second quintile, 29.6 to get to the\nthird quintile, 53.4 years to enter the fourth, and 103.6 years to reach\nthe richest quintile.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regional context and Moran's Is\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus far we have treated all the spatial units as independent to\nestimate the transition probabilities. This hides an implicit\nassumption: the movement of a spatial unit in the income distribution is\nindependent of the movement of its neighbors or the position of the\nneighbors in the distribution. But what if spatial context matters??\n\nWe could plot the choropleth maps of per capita incomes in US to get a\nfirst impression of the spatial distribution.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from splot import mapping as maps\nimport pandas as pd\nimport libpysal\nimport libpysal.io.geotable as pdio\ndata_table = pdio.read_files(libpysal.examples.get_path('us48.shp'))\nincome_table = pd.read_csv(libpysal.examples.get_path(\"usjoin.csv\"))\ncomplete_table = data_table.merge(income_table,left_on='STATE_NAME',right_on='Name')\nprint(complete_table.columns)\n\nindex_year = range(1929,2010,15)\nfig, axes = plt.subplots(nrows=2, ncols=3,figsize = (15,7))\nfor i in range(2):\n    for j in range(3):\n        ax = axes[i,j]\n        maps.geoplot(complete_table, col=str(index_year[i*3+j]),ax=ax,classi=\"Quantiles\")\n        ax.set_title('Per Capita Income %s Quintiles'%str(index_year[i*3+j]))\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is quite obvious that the per capita incomes are not randomly\ndistributed: we could spot clusters in the mid-south, south-east and\nnorth-east. Let's proceed to calculate Moran's I, a widely used measure\nof global spatial autocorrelation, to aid the visual interpretation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from esda.moran import Moran\nimport matplotlib.pyplot as plt\n# %matplotlib inline\nw = libpysal.open(libpysal.examples.get_path(\"states48.gal\")).read()\nw.transform = 'R'\nmits = [Moran(cs, w) for cs in pci]\nres = np.array([(mi.I, mi.EI, mi.seI_norm, mi.sim[974]) for mi in mits])\nyears = np.arange(1929,2010)\nfig, ax = plt.subplots(nrows=1, ncols=1,figsize = (10,5) )\nax.plot(years, res[:,0], label='Moran\\'s I')\n#plot(years, res[:,1], label='E[I]')\nax.plot(years, res[:,1]+1.96*res[:,2], label='Upper bound',linestyle='dashed')\nax.plot(years, res[:,1]-1.96*res[:,2], label='Lower bound',linestyle='dashed')\nax.set_title(\"Global spatial autocorrelation for annual US per capita incomes\",fontdict={'fontsize':15})\nax.set_xlim([1929,2009])\nax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above figure we could observe that Moran's I value was always\npositive and significant for each year across 1929-2009. In other words,\nUS regional income series are not independent of each other and regional\ncontext could be important in shaping the regional income dynamics.\nHowever, the classic Markov approach is silent on this issue. We turn to\nthe spatially explict Markov methods - **Spatial Markov** and **LISA\nMarkov** - for an explicit incorporation of space in understanding US\nregional income distribution dynamics.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Spatial Markov <http://onlinelibrary.wiley.com/doi/10.1111/j.1538-4632.2001.tb00444.x/full>`__\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    giddy.markov.Spatial_Markov(self, y, w, k=4, permutations=0, fixed=False, variable_name=None)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Spatial Markov is an extension to class Markov allowing for a more\ncomprehensive analysis of the spatial dimensions of the transitional\ndynamics (Rey, 2001). Here, whether the transition probabilities are\ndependent on regional context is investigated and quantified. Rather\nthan estimating one transition probability matrix, spatial Markov\nrequires estimation of $k$ transition probability matrices, each\nof which is conditional on the regional context at the preceding period.\nThe regional context is usually formalized by spatial lag - the weighted\naverage income level of neighbors:\n\n\\begin{align}z_{r,t} = \\sum_{s=1}^{n} w_{r,s} y_{s,t}\\end{align}\n\nwhere $W$ is the spatial weight matrix and $w_{r,s}$\nrepresents the weight that spatial unit $s$ contributes to the\nlocal context of spatial unit $r$ at time period $t$.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the construction of a **Markov** instance, we could create a\n**Spatial Markov** instance by utilizing the $Spatial\\_Markov$\nclass in **giddy**. The only difference between the adoption of\n$Markov$ and $Spatial\\_Markov$ class is that the latter\naccepts the original continuous income data while the former requires a\npre-classification/discretization. In other words, here we do not need\nto apply the classification methods in\n`**mapclassify** <https://github.com/pysal/mapclassify>`__ as we did\nearlier. In fact, the **Spatial Markov** class nested the quantile\nclassification methods and all we need to do is set the desired number\nof classes $k$ when creating the $Spatial\\_Markov$ instance.\nHere, we set $k=5$ (quintile classes) as before.\n\nDifferent from before, quintiles are defined for the pooled relative\nincomes (by standardizing by each period by the mean). This is achieved\nby setting the parameter $fixed$ as *True*.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sm = giddy.markov.Spatial_Markov(rpci.T, w, fixed = True, k = 5) # spatial_markov instance o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can next examine the global transition probability matrix for\nrelative incomes.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(sm.p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Spatial Markov allows us to compare the global transition dynamics\nto those conditioned on regional context. More specifically, the\ntransition dynamics are split across economies who have spatial lags in\ndifferent quintiles at the preceding year. In our example we have 5\nclasses, so 5 different conditioned transition probability matrices are\nestimated - P(LAG0), P(LAG1), P(LAG2), P(LAG3), and P(LAG4).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The probability of a poor state remaining poor is 0.963 if their\nneighbors are in the 1st quintile and 0.798 if their neighbors are in\nthe 2nd quintile. The probability of a rich economy remaining rich is\n0.977 if their neighbors are in the 5th quintile, but if their neighbors\nare in the 4th quintile this drops to 0.903.\n\nWe can also explore the different steady state distributions implied by\nthese different transition probabilities:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(sm.S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The long run distribution for states with poor (rich) neighbors has\n0.435 (0.018) of the values in the first quintile, 0.263 (0.200) in the\nsecond quintile, 0.204 (0.190) in the third, 0.0684 (0.255) in the\nfourth and 0.029 (0.337) in the fifth quintile. And, finally the\nspatially conditional first mean passage times:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(sm.F)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "States in the first income quintile with neighbors in the first quintile\nreturn to the first quintile after 2.298 years, after leaving the first\nquintile. They enter the fourth quintile 80.810 years after leaving the\nfirst quintile, on average. Poor states within neighbors in the fourth\nquintile return to the first quintile, on average, after 12.88 years,\nand would enter the fourth quintile after 28.473 years.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tests for this conditional type of spatial dependence include Likelihood\nRatio (LR) test and $\\chi^2$ test (Bickenbach and Bode, 2003) as\nwell as a test based on information theory (Kullback et al., 1962). For\nthe first two tests, we could proceed as follows to acquire their\nstatistics, DOF and p-value.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "giddy.markov.Homogeneity_Results(sm.T).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above summary table, we can observe that the observed LR test\nstatistic is 170.659 and the observed $\\chi^2$ test statistic is\n200.624. Their p-values are 0.000, which leads to the rejection of the\nnull hypothesis of conditional spatial independence.\n\nFor the last (information theory-based) test, we call the function\n$kullback$. The result is consistent with LR and $\\chi^2$\ntests. As shown below, the observed test statistic is 230.03 and its\np-value is 2.22e-16, leading to the rejection of the null.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(giddy.markov.kullback(sm.T))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LISA Markov\n~~~~~~~~~~~\n\n::\n\n    giddy.markov.LISA_Markov(self, y, w, permutations=0, significance_level=0.05, geoda_quads=False)\n\nThe Spatial Markov conditions the transitions on the value of the\nspatial lag for an observation at the beginning of the transition\nperiod. An alternative approach to spatial dynamics is to consider the\njoint transitions of an observation and its spatial lag in the\ndistribution. By exploiting the form of the static LISA and embedding it\nin a dynamic context we develop the LISA Markov in which the states of\nthe chain are defined as the four quadrants in the Moran scatter plot,\nnamely, HH(=1), LH(=2), LL(=3), HL(=4). Continuing on with our US\nexample, the LISA transitions are:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lm = giddy.markov.LISA_Markov(pci.T, w)\nprint(lm.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The LISA transitions are:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(lm.transitions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the estimated transition probability matrix is:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(lm.p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The diagonal elements indicate the staying probabilities and we see that\nthere is greater mobility for observations in quadrants 2 (LH) and 4\n(HL) than 1 (HH) and 3 (LL).\n\nThe implied long run steady state distribution of the chain is:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(lm.steady_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "again reflecting the dominance of quadrants 1 and 3 (positive\nautocorrelation). The first mean passage time for the LISAs is:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(giddy.ergodic.fmpt(lm.p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To test for dependence between the dynamics of the region and its\nneighbors, we turn to $\\chi^2$ test of independence. Here, the\n$\\chi^2$ statistic, its p-value and degrees of freedom can be\nobtained from the attribute $chi\\_2$. As the p-value is 0.0, the\nnull of independence is clearly rejected.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(lm.chi_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next steps\n~~~~~~~~~~\n\n-  Simulation/prediction of Markov chain and spatial Markov chain\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n~~~~~~~~~~\n\n-  Rey, S. J. 2001. \u201c\\ `Spatial Empirics for Economic Growth and\n   Convergence <http://onlinelibrary.wiley.com/doi/10.1111/j.1538-4632.2001.tb00444.x/full>`__.\u201d\n   Geographical Analysis 33 (3). Wiley Online Library: 195\u2013214.\n-  Bickenbach, F., and E. Bode. 2003. \u201c\\ `Evaluating the Markov Property\n   in Studies of Economic\n   Convergence <http://journals.sagepub.com/doi/abs/10.1177/0160017603253789?journalCode=irxa>`__.\u201d\n   International Regional Science Review 26 (3): 363\u201392.\n-  Kullback, S., M. Kupperman, and H. H. Ku. 1962. \u201c\\ `Tests for\n   Contingency Tables and Markov\n   Chains <https://www.jstor.org/stable/1266291?seq=1#page_scan_tab_contents>`__.\u201d\n   Technometrics: A Journal of Statistics for the Physical, Chemical,\n   and Engineering Sciences 4 (4). JSTOR: 573\u2013608.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}